{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install elasticsearch\n",
    "pip install gensim\n",
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from elasticsearch import Elasticsearch\n",
    "from gensim.models import FastText\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Preprocess the documents\n",
    "preprocessed_docs = []\n",
    "for doc in newsgroups.data:\n",
    "    # Tokenize the document\n",
    "    tokens = gensim.utils.simple_preprocess(doc.lower())\n",
    "    # Remove stop words and stem the tokens\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    # Join the stemmed tokens back into a string\n",
    "    preprocessed_doc = ' '.join(stemmed_tokens)\n",
    "    preprocessed_docs.append(preprocessed_doc)\n",
    "\n",
    "# Train the FastText model\n",
    "model = FastText(preprocessed_docs, vector_size=300, window=5, min_count=5, workers=4)\n",
    "\n",
    "# Save the model to a binary file\n",
    "model.save('model.bin')\n",
    "\n",
    "# Initialize Elasticsearch client with URL\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "# Delete the index if it already exists\n",
    "index_name = 'my_index'\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "# Create index with appropriate mappings\n",
    "index_mappings = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'text': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'vector': {\n",
    "                'type': 'dense_vector',\n",
    "                'dims': 300\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es.indices.create(index=index_name, body=index_mappings)\n",
    "\n",
    "# Iterate over preprocessed documents and generate vectors\n",
    "for i, doc in enumerate(preprocessed_docs):\n",
    "    # Split the preprocessed document into tokens\n",
    "    tokens = doc.split()\n",
    "    # Generate the vector for the document by averaging the vectors of its tokens\n",
    "    vector_sum = 0\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vector_sum += model.wv[token]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        vector = vector_sum / count\n",
    "        # Store the document and its vector in the Elasticsearch index\n",
    "        es.index(index=index_name, id=i, body={'text': doc, 'vector': vector.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector: [ 1.54352179e-04  8.35887040e-05  3.29365546e-04  7.56893132e-05\n",
      " -2.44254097e-05  1.18353482e-05  2.91574070e-05 -1.24124155e-04\n",
      "  3.81721213e-04  3.33571254e-04  2.02411407e-04  3.98195334e-06\n",
      " -1.70753192e-04 -1.60401014e-05  5.46945266e-05  5.21716604e-04\n",
      "  2.36337393e-04 -1.52272303e-04 -2.55212566e-04 -1.44240810e-04\n",
      " -1.96665042e-05  3.61155311e-04 -2.38097418e-05 -1.40672913e-04\n",
      "  1.79930066e-04  1.85321624e-05 -2.27287819e-04 -5.39382600e-05\n",
      "  1.11497655e-04  4.09221713e-04 -2.11956183e-04 -1.35426526e-04\n",
      " -9.27258952e-05 -3.18381390e-05  8.01294373e-05 -2.11412858e-04\n",
      " -1.09799308e-04  4.61659598e-04  3.45820270e-04 -5.60979424e-05\n",
      " -4.39650466e-05  2.40595240e-04  2.59514200e-04  2.14081709e-04\n",
      " -2.40453319e-05  1.07260828e-04 -4.91869105e-05  1.49703003e-04\n",
      "  9.36621000e-05  4.11564761e-05 -3.22865642e-04 -7.14768394e-05\n",
      " -1.37804644e-04 -1.30039130e-04  3.40868683e-05 -6.06160502e-05\n",
      " -1.33106121e-04  2.94821744e-04  4.93076441e-05 -1.12611044e-04\n",
      " -1.35913011e-04 -3.51269235e-04 -1.88590580e-04 -2.74959253e-04\n",
      "  1.75769324e-04  1.60799056e-04  2.49257246e-05  1.06684303e-04\n",
      " -3.54277669e-04 -2.75487313e-04 -2.94953876e-04  2.98891227e-05\n",
      "  2.61825306e-04  1.85359226e-04 -1.27349718e-04 -1.02576210e-04\n",
      " -3.15470679e-05  1.38110205e-04 -3.35800833e-05 -1.87638594e-04\n",
      "  2.46622454e-04 -2.24302174e-04  3.33644639e-05 -7.05861521e-06\n",
      " -7.89485682e-07 -8.08126060e-05 -9.94396942e-06  2.22056115e-04\n",
      " -6.18029881e-05 -3.18575359e-04  2.72059056e-04  5.54047074e-05\n",
      " -2.72416015e-04 -2.60778670e-05 -6.38275014e-05  1.92019419e-04\n",
      "  1.89334576e-04 -1.95010452e-05  7.66668963e-05 -6.39785940e-05\n",
      " -1.35384325e-04  1.32628411e-04 -1.94782973e-04 -5.19984133e-05\n",
      " -7.40484320e-05 -5.83869187e-05 -2.59124907e-04  2.16090280e-04\n",
      " -2.64900911e-04  1.33339330e-04 -2.37740387e-04  7.79450711e-05\n",
      " -1.45184604e-04 -2.78520820e-05  1.89407874e-04  1.72278116e-04\n",
      " -1.59455129e-04 -1.64634635e-04  1.22434139e-04 -2.19435009e-04\n",
      "  8.43711023e-05  1.54882837e-05  1.46313920e-04 -3.31259216e-04\n",
      " -2.55909457e-04  2.72129488e-04 -2.10658909e-04 -3.61330422e-05\n",
      " -9.75066869e-05  1.09890520e-04  3.55922093e-04 -5.07824952e-05\n",
      "  1.53172237e-04  1.03994760e-04 -1.53304863e-04  1.35621085e-04\n",
      "  2.10084501e-04  4.95096901e-05 -1.94919543e-04  1.80574025e-05\n",
      " -4.44403631e-05  3.60313774e-04 -8.85440531e-05 -8.15530148e-05\n",
      " -1.41444019e-04  1.49813686e-05  2.64541799e-04  1.34029659e-04\n",
      " -3.71905708e-06 -5.40003093e-05  1.83823590e-06  3.12651420e-04\n",
      "  9.97213210e-05 -5.30784600e-04 -6.92555186e-05  1.11671063e-04\n",
      "  1.36570052e-05  7.05200218e-05  1.47326238e-04  4.36463772e-04\n",
      " -1.43568059e-05  1.05228020e-04  8.06734461e-05  8.40398934e-05\n",
      "  2.63713533e-04  2.55877472e-04 -1.75133653e-04  1.92578940e-04\n",
      " -7.64661308e-05 -7.39012030e-05 -1.18275435e-04 -1.35332884e-05\n",
      "  4.56920709e-04 -1.01954004e-06 -8.79318759e-05  2.02136318e-04\n",
      "  1.72209810e-04 -8.82516833e-05 -1.28109765e-04  3.62592909e-05\n",
      " -1.16004485e-04 -1.19225144e-04  2.92544119e-05  1.52560795e-04\n",
      " -4.24767313e-05  5.95221172e-05  6.67325658e-05 -1.83195327e-04\n",
      "  2.57164735e-04  2.73373676e-04  2.01678457e-04 -5.09073470e-05\n",
      " -2.74777034e-04  1.37643743e-04 -6.29523929e-05 -1.93234682e-05\n",
      "  1.63304765e-04  5.05309072e-05 -3.79020639e-04 -1.42578301e-05\n",
      "  1.19256430e-04 -1.09222143e-04 -2.34707870e-04 -3.23882123e-04\n",
      "  3.29884468e-04 -7.79134061e-05 -2.00393333e-04  3.26617810e-05\n",
      "  3.76640848e-04 -5.86688984e-05  1.61363700e-04 -1.35014227e-04\n",
      " -4.99725684e-05  9.17417856e-05  9.06750699e-07  6.34530579e-06\n",
      " -1.98604903e-04 -2.13304331e-04  1.03211569e-04  7.49492538e-05\n",
      " -1.66139289e-04 -3.13755387e-04 -1.53465808e-04 -6.68270950e-05\n",
      " -6.89408116e-05 -2.31872793e-04  2.58835411e-04  1.39660973e-04\n",
      "  7.20878670e-05  4.52100676e-06  3.52330506e-04  2.85846269e-04\n",
      "  1.20398028e-04 -2.03864074e-05 -4.93113330e-05  3.25102556e-05\n",
      "  1.82200329e-05  1.61708114e-04  1.33362322e-04 -3.15001816e-04\n",
      " -3.52638490e-05  1.36054980e-04 -5.85523912e-06  3.34048411e-04\n",
      "  1.06698593e-04 -9.29106536e-05 -3.30559938e-04 -6.13070588e-05\n",
      "  1.17605727e-04  1.95331057e-04 -1.18512791e-04 -7.60748590e-05\n",
      " -7.99452391e-05  1.41638040e-04  1.67032253e-04 -6.64975523e-05\n",
      "  7.68842074e-06 -1.74421089e-04 -2.11880848e-04  1.00875681e-04\n",
      "  3.02546614e-05  6.60388323e-05  1.99406364e-04  6.25468820e-05\n",
      "  8.46287003e-05  2.75720551e-04 -2.26224161e-04 -5.80549895e-05\n",
      "  4.18798663e-05  1.05034946e-04 -2.19999492e-04  9.06378118e-05\n",
      "  2.20865579e-04 -3.51402850e-05  1.30733883e-04  3.25724832e-04\n",
      " -3.40255356e-05 -2.47748278e-04 -1.16480354e-04 -1.88400692e-04\n",
      "  1.72620683e-04  1.68789455e-04  1.78936243e-04  1.13751281e-04\n",
      " -1.82344898e-04 -8.98636572e-05 -1.14207447e-04 -8.92524349e-06\n",
      "  2.78196763e-04 -1.71934604e-04 -2.38915352e-04  2.80488923e-04\n",
      " -1.75277382e-04  1.03770908e-04  1.82620439e-04  1.32585628e-04\n",
      " -1.31290028e-04 -1.72525790e-04 -1.81951298e-04  1.05102838e-04]\n",
      "Top 10 most similar documents:\n",
      "1. speedi engr latech edu speedi mercer subject boom dog attack organ louisiana tech univers line nntp post host bhm spc engr latech edu articl apr dsd es com bgardner bambam es com blain gardner write articl bong kfp slac mac slac stanford edu bong slac stanford edu eric bong write articl gp cbnew cb att com nak cbnew cb att com neil kirbi wrote bicycl techniqu ve emploi us frame mount tire pump fend dog attack bayonet factori scabbard swedish mouser mount handlebar zuki blade long arm thank dod technician dr speed student stolen taglin hei think naahh\n",
      "2. asper calvin uucp alan asper subject boom dog attack organ usr lib new organ line nntp post host calvin sbc com articl bong kfp slac mac slac stanford edu bong slac stanford edu eric bong write nice ridin tex us california dmv recommend techniqu slow aproach said dog wick pass ve standard strategi taught cuz told illinoi msf class work satisfact kick shit rabid hell beast alan\n",
      "3. pkr slacvm slac stanford edu patrick krejcik subject file server mac articl pkrmac pkr organ slac line saw articl new line mac configur work optim file server know detail\n",
      "4. bgardner bambam es com blain gardner subject boom dog attack nntp post host bambam organ evan sutherland corpor line articl bong kfp slac mac slac stanford edu bong slac stanford edu eric bong write articl gp cbnew cb att com nak cbnew cb att com neil kirbi wrote work rd lean dog modul throttl ankl ahead teeth second warm pipe firmli wedg shoulder turn face sidewai warm got mouth nose muzzl burn pipe bicycl techniqu ve emploi us frame mount tire pump fend dog attack brother spent lot time practic bizzar trick megabuck micromass bike said repel dog attack pick rear bike smack dog head rear wheel dog idea hit fled rapidli jump garbag can ramp think care try motorcycl telephon work better tire pump unfair ve seen dog us phone blain gardner evan sutherland bgardner dsd es com\n",
      "5. ronaldw sco com ronald wong subject powerbook duo batteri articl ringo ronaldw distribut na organ sco develop relat line articl vr eb usenet uc indiana edu kssimon silver uc indiana edu kenneth steven simon wrote hade coo dartmouth edu brian hugh write knowledg wai fulli discharg duo batteri program powerstrip freewar option call quick discharg mac archiv probabl sumex aim stanford edu mac archiv umich edu good luck kenneth simon depart sociolog kssimon indiana edu indiana univers hidden option powerstrip mr caputo right quick discharg option definit mac archiv umich edu caus submit ron wong santa cruz oper net comm segment mgr encin street po box fax devprogram market mgr santa cruz ca mail uunet sco ronaldw ronaldw sco com\n",
      "6. bmdelan midwai uchicago edu brian man delanei subject result sci life extens pass organ univers chicago line nntp post host rodan uu net vote creat propos group sci life extens affirm ye vote vote follow list peopl vote vote ye peopl vote bailei utpapa ph utexa edu ed bailei barkdol lepomi psych upenn edu edwin barkdol msb sq com mark brader carr acsu buffalo edu dave carr desj ccr ida org david desjardin jbh anat umsm edu jame hutchin rsk gynko circ upenn edu rich kulawiec stu valinor mythic com stu labovitz lau ai sri com stephen lau plebrun minf vub ac philipp lebrun jmaynard nyx cs du edu jai maynard emcguir intellect com ed mcguir rick crick ssctr bcm tmc edu richard miller smarri zooid guild org marc moorcroft dmosher nyx cs du edu david mosher ejo kaja gi alaska edu eric olson hmpetro mosaic uncc edu herbert petro smith una yale edu una smith mmt redbrick com maxim taksar kc zp urlich smurf sub org matthia urlich ac umbc edu franci uy werner soe berkelei edu john werner wick netcom com potter wickwar ggw wolv durham nc gregori woodburi wright bnr uk wright yarvin norman cs yale edu norman yarvin ask cblph att com spm opal cs virginia edu peopl vote ye fsspr acad alaska edu hardcor alaskan kalex eec umich edu ken alexand ph fht sdcc ucsd edu alex aumann franklin balluff syntex com franklin balluff barash umbc edu mr steven barash build alan ingr com alan barksdal build lion therat kludg com john barlow pbarto uceng uc edu paul barto ryan bayn canrem com ryan bayn mignon shannon jpl nasa gov mignon belongi beaudot tirf grenet fr william beaudot lavb lise unit olav benum ross bryson demon uk ross beresford ben best canrem com ben best levi happi man com levi bitanski jsb dagda eng sun com jame blomgren gbloom nyx cs du edu gregori bloom mbrader netcom com mark brader ebrandt jarthur claremont edu eli brandt doom leland stanford edu joseph brenner rc po apana org au robert cardwel jeffjc binklei cs mcgill ca jeffrei chanc sasha cs umb edu alexand chislenko mclark world std com maynard clark compuserv com clifford coleman twinsun com mike coleman steve constel ecn uoknor edu steve coltrin collier ivori rtsg mot com john collier compton plain nodak edu curti compton bobc master cna tek com bob cook cordel shaman nexagen com bruce cordel cormierj er umontr ca cormier jean marc djcoyl macc wisc edu dougla coyl dass student tc umn edu john dassow bdd onion eng hou compaq com bruce davi demonn emunix emich edu kenneth jubal demonn desilet sj at slb com mark desilet markd sco com mark diekhan kari teracon teracon com kari dubbelman lhdsy cyberia hou chevron com hwdub uunet uu net dub dublin willdy helio unl edu dye yegan jove dnet measurex com juno measurex com terri egan eder hsvaic boe com dani eder glenn magenta hq ileaf com glenn ellingson farrar adaclab com richard farrar ghsvax hal uunet uu net hal finnei lxfogel srv pacbel com lee fogel afoxx foxxjac ingr com foxx disc dla mil sam frajerman sppb mpf medg lc mit edu michael frank martin franklin corp sun com martin franklin tiff cs ucla edu tiffani frazier ergo cs cmu edu ail freeman timothy_freeman ergo cs cmu edu tim freeman gt prism gatech edu geoff georg mtvdjg rivm nl daniel gijsber exusag exu ericsson se serena gilbert rlglend netcom com robert lewi glenden goetz cs buffalo edu phil goetz goolsbi dg rtp dg com chri goolsbi dgordon crow omni jp david gordon bgraham eri demon uk robert graham sascsg unx sa com cynthia grant green srilanka island com robert greenstein johng oc orst edu john gregor roger netcom com roger gregori evan ron cs yale edu ron hale evan brent vpnet chi il brent hansen ron hai med umich edu ron hai akh empress gvg tek com anna hayn clari qm bob_hearn am arc nasa gov robert hearn fheyligh vnet vub ac franci heylighen hin midwai uchicago edu hindman fish casbah acn nwu edu carwil jame janzen mprgate mpr ca martin janzen karp skcla monsanto com jefferi karp rk elsegundoca ncr com richard kelli merklin gnu ai mit edu ed kemo kessner rintintin colorado edu kessner eric mapam csv warwick ac uk mr khwaja koski sunset cs utah edu keith koski kathi bridg com kathi kramer benkrug jupit fnbc com ben krug farif eskimo com david kunz edsr edsdrd sel uunet uu net steve lang pa_hcl meceng coe northeastern edu henri leong linton pmm cam ac uk steve linton alopez cs ep utexa edu alejandro lopez kfl access digex com keith lynch kamchar msu edu charl macdonald rob vi toronto edu robert majka phil starconn com phil mark cam jackatak raider net cameron marshal mmai mcd intel com mike drac uumem chi il bruce maynard discg disc dla mil john mccarrick xyzzi imagen com david mcintyr cuhe csv warwick ac uk malcolm mcmahon mcpherso macvax ucsd edu john mcpherson merkl parc xerox com ralph merkl eric synopsi com eric messick pmetzger shearson com perri metzger gmichael vmd cso uiuc edu gari michael dat ma ludat lth se asker mikael millerl wilma wharton upenn edu loren miller minski media mit edu marvin minski pmorri lamar colost edu paul morri mark_muhlestein novel com mark muhlestein david staff udc upenn edu david murrai ganannei mosaic uncc edu glenn nannei anthoni meaddata com anthoni napier dniman panther win net donald niman nistuk unixg ubc ca richard nistuk jonathan rmit edu au jonathan donnel martino gomez jpl nasa gov martin olah cpatil leland stanford edu christoph kashina patil crp erfsi boe com chri payn sharon acri fr sharon peleg php rhi hi petur henri petersen chrisp efi com chri phoenix pierc cs ucla edu brad pierc juliu math utah edu juliu pierc dplatt cellar org doug platt mitchel porter lambada oit unc edu mitchel porter cpresson jido ingr com craig presson price price demon uk michael clive price uicvm bitnet edward proctor stevep deckard work ti com steve pruitt mjquinn pucc bitnet michael quinn rauss nvl armi mil patrick rauss remk cs tu berlin jan remk ag yfn ysu edu barri rodin ksackett cs uah edu karl sackett rc cs arizona edu richard schroeppel fschulz pyramid com frank schulz kw thunder island kalamazoo mi karel sebek bseewald gozer idbsu edu brad seewald shapard manta nosc mil thoma shapard hab panix com harri shapiro muir idiom berkelei ca david muir sharnoff dasher sf ca anton sherwood zero netcom com richard shiflett ap brownvm bitnet elain shiner robsho robsho auto trol com robert shock rshvern gmuvax gmu edu rob shvern wesiegel cie uoregon edu william siegel ggyygg mixcom mixcom com kenton sinner bsmart bsmart tti com bob smart toni ariel uc unimelb edu au anthoni david smith sgccsn citecuc citec oz au shayn noel smith dsnider beta triciti wsu edu daniel snider snyderg spot colorado edu snyder gari edwin jr blupe ruth fullfe com brian arthur stewart lhdsy usmi midland chevron com tsfsi uunet uu net sigrid stewart nat netcom com nathaniel stitt tp biosym com tom stockfisch stodolsk andromeda rutger edu david stodolski gadget dc warwick ac uk steve strong carei cs ucla edu carei sublett jsuttor netcom com jeff suttor swain cernapo cern ch john swain szabo techbook com nick szabo ptheriau netcom com chri theriault ak yfn ysu edu chri thompson gunnar thoresen bio uio gunnar thoresen dreamer uxa cso uiuc edu andrew trapp jerri cse lbl gov jerri tuni music parcom ernet rajeev upadhy treon washington edu treon verderi evor magnu ac ohio state edu eric vore uicvm bitnet howard wachtel susan wpi wpi edu susan wade compuserv com paul wakfer ewalk berkle edu elain walker jew rt sunquest com jame ward jeremi ai mit edu jeremi wertheim bw ws torreypinesca ncr com bruce white weed strobe atc olivetti com mark wiedman wiesel elisha cs yale edu elisha wiesel willingp gar union edu will paul smw alcor concordia ca steven winikoff wright hicomb hi com david wright ebusew anah ericsson com stephen wright liquidx cnexu ct com liquid xakelli uivlsisl csl uiuc edu michael xakelli cs cs brown edu ion yannopoulo yazz lccsd sd locu com bob yazz lnz lucid com leonard zubkoff rse npd ufp br adwyer mason gmu edu art embl hamburg atfurman cup portal com billw attmail att com carl red dragon umbc edu carlf ai mit edu cccbb chri thompson uceng uc edu ccgarcia mizzou bitnet clayb cellar org dack permanet org daedalu netcom com danielg autodesk com dave cup portal com f_griffith ccsvax sfasu edu garcia husc harvard edu gav houxa att com hammar cs unm edu herbison lassi ucx lkg dec com hhuang athena mit edu hkhenson cup portal com irv happi man com jeckel amugw aichi med ac jp jg merit edu jmeritt mental mitr org cup portal com kqb whscad att com lpomeroi velara sim es com lubkin apollo hp com kunert wustlb wustl edu linyard_m xeno logica uk michel wrightwatson att com moselecw elec canterburi ac nz naoursla eo ncsu edu ng husc harvard edu pase dchapman uwm edu pocock math utah edu rudi hsd uvic ca scottjor delphi com stanton id com steveha microsoft com stu discov wright edu syang es_a xerox com tim hrubi com todd kaufmann fussen mt cs cmu edu tom geni slh udel edu uc mizzou bitnet wmiller clust clemson edu yost mv adob com group pass count peopl email address brian bmdelan midwai uchicago edu\n",
      "7. swkirch sun nrl navi mil steve kirchoef subject rd cfv vote ack misc health diabet organ naval research laboratori electron scienc technolog divis line nntp post host rodan uu net final vote creation newsgroup misc health diabet mass acknowledg valid vote receiv april th gmt appear end post check list sure vote regist read instruct vote carefulli follow precis certain place proper vote instruct vote place vote creation misc health diabet send email messag ye sun nrl navi mil place vote creation misc health diabet send email messag sun nrl navi mil content messag contain line vote misc health diabet propos email messag sent address constitut unambigu uncondit vote newsgroup creation propos condit vote accept vote email address count mail repli post return event vote place individu recent vote count vote continu gmt apr vote accept date administr inquiri pertain cfv email swkirch sun nrl navi mil propos charter appear charter misc health diabet unmoder purpos misc health diabet provid forum discuss issu pertain diabet manag diet activ medicin schedul blood glucos control exercis medic breakthrough group address issu manag type insulin depend type ii non insulin depend diabet technic discuss gener support discuss relev diabet welcom post misc heath diabet intend discuss purpos wai constru medic advic diabet medic condit requir direct supervis primari health care physician end charter follow individu sent valid vote bmu vm csd mu edu satterle wj loki cc pdx edu jim william ac freenet carleton ca colin henein ad cat axel dunkel al academ mty itesm mx jesu eugenio nchez pe anugula badland nodak edu ramakrishna reddi anugula app sneak kodak com robert app arperd mik uki edu alicia perdu baind gov ca dave bain balamut morri hac com morri balamut bch juliet caltech edu bgain ollamh ucd brian gain bjorn larsen delab sintef bobw hpsadwc sad hp com bob waltenspiel bruce uxb liverpool ac uk bruce bspencer binklei cs mcgill ca brian spencer cline usceast cs scarolina edu ernest cline coleman twin twinsun com mike coleman compass da com tomd compass da com thoma donnelli csc coast ucsd edu charl coughran curtech sb unh edu stephani bradlei swift debrum msgate corp appl com debrum brenda dlb fanni wash inmet com david barton dlg midwai uchicago edu deborah lynn gillaspi dougb comm mot com dougla bank ed titipu resun com edward reid edmoor hpvclc vcd hp com ed moor ejo kaja gi alaska edu eric olson emcguir intellect com ed mcguir ewc hplb hpl hp com enrico coiera feathr bluejai ampakz enet dec com franklig ga uug arizona edu gregori franklin fsspr acad alaska edu hardcor alaskan gabe angu mi org gabe helou gasp medg lc mit edu isaac kohan gasp medg lc mit edu isaac kohan geir millstein tf tele ggurman cori berkelei edu gail gurman ggw wolv durham nc gregori woodburi greenlaw oasi dt navi mil leila thoma grm andrew cmu edu gretchen miller halderc cs rpi edu handelap duvm bitnet pucc princeton edu phil handel hansenr ohsu edu hc nyongwa cam org hc hed chrisco nrl navi mil hubert hed herbison lassi ucx lkg dec com hmpetro mosaic uncc edu herbert petro hosch iscsvax uni edu hrubin pop stat purdu edu herman rubin hudsoib auducadm duc auburn edu ingrid hudson huff mcclb med nyu edu edward huff huffman ingr com gari huffman huynh_ estd nrl navi mil minh huynh ishbeld cix compulink uk ishbel donkin jame langdel eng sun com jame langdel jamyer netcom com john myer jc crosfield uk jerri cullingford jesup cbmvax cbm commodor com randel jesup jjmorri gandalf rutger edu joyc morri joep dap csiro au joe petranov john burton acenet auburn edu john burton jr johncha comm mot com jorgensonk cc uvcc edu jpsum mik uki edu joei sum jtm ucsfvm ucsf edu john maynard julien skcla monsanto com kaminski netcom com peter kaminski kerri citr uq oz au kerri raymond kieran world std com aaron dickei knauer cs uiuc edu rob knauerhas kolar spot colorado edu jennif lynn kolar kriguer tc com marc kriguer lau ai sri com stephen lau lee hal com lee boylan lmt po cwru edu luni lehigh edu lusgr chili cc lehigh edu stephen roseman beamish in gu edu au marilyn beamish rich en gu edu au mauric rich maa cdfsga fnal gov peter maa macridis_g kosmo wcc govt nz gerri macridi markv hpvcivm vcd hp com mark vanderford maschler vm huji ac il mcb net bio net michael berch mcdai ux cso uiuc edu mcookson flute calpoli edu mfc isr harvard edu mauricio contrera mg wpi edu martha gunnarson mhollowa libserv ic sunysb edu michael hollowai misha abacu concordia ca misha glouberman mjb cs brown edu manish butt moflngan vax tcd muir idiom berkelei ca david muir sharnoff nanci block eng sun com nanci block ndallen node hub org nigel allen nlr nei nih gov rohrer nathan owen cookiemonst cc buffalo edu owen pam hpfcmp fc hp com pam sullivan papresco undergrad math uwaterloo ca paul prescod paslowp cs rpi edu pillinc gov ca christoph pill pkane cisco com peter kane popelka odysseu uchicago edu glenn popelka pulkka cs washington edu aaron pulkka pwatkin med unc edu pat watkin rbnsn mosaic shearson com ken robinson rick crick ssctr bcm tmc edu richard miller robyn media mit edu robyn kozierok rolf green mathematik uni stuttgart rolf schreiber sageman cup portal com sasjc unx sa com joan stout scottjor delphi com scrl hplb hpl hp com sc vecti demon uk stuart squibb shan techop crai com sharan kalwani sharen iscnvx lmsc lockhe com sharen rund shazam unh edu matthew thompson shipman csab larc nasa gov floyd shipman shoppa erin caltech edu tim shoppa slilli cs bradlei edu susan lilli steveo world std com steven orr surendar ivi wpi edu surendar chandra swkirch sun nrl navi mil steven kirchoef s_fagan twu edu taryn arizvm ccit arizona edu taryn westergaard thoma taylor gagm chi il thoma taylor tima cfsmo honeywel com timothi aanerud tsamuel gollum relai nswc navi mil toni samuel uicvm uic edu jacob vstern gte com vanessa stern wahlgren haida van wti com jame wahlgren waterf pyrsea sea pyramid com dougla waterfal weineja teomail jhuapl edu wgrant informix com william grant yeager mscf med upenn edu yozzo watson ibm com ralph yozzo beach utmb edu molli hamilton steve kirchoef code kirchoef estd nrl navi mil naval research laboratori microwav technolog branch washington dc electron sci tech divis\n",
      "8. swkirch sun nrl navi mil steve kirchoef subject result misc health diabet pass organ naval research laboratori electron scienc technolog divis line nntp post host rodan uu net vote creation newsgroup misc health diabet end gmt apr time total respons receiv consist vote newsgroup creation vote newsgroup creation guidelin usenet group creation respons constitut pass vote delai allow time net respond result newsgroup misc health diabet creat check vote acknowledg list sure vote receiv properli credit inconsist error report swkirch sun nrl navi mil email want thank particip discuss vote newsgroup propos follow vote summari vote receiv newsgroup creation cline usceast cs scarolina edu ernest cline coleman twin twinsun com mike coleman ejo kaja gi alaska edu eric olson elharo shiva njit edu elliott rusti harold emcguir intellect com ed mcguir hansenr ohsu edu hmpetro mosaic uncc edu herbert petro jjmorri gandalf rutger edu joyc morri julian bongo tele com julian macassei knauer cs uiuc edu rob knauerhas lau ai sri com stephen lau macridis_g kosmo wcc govt nz gerri macridi owen cookiemonst cc buffalo edu owen rick crick ssctr bcm tmc edu richard miller vote receiv newsgroup creation bmu vm csd mu edu satterle wj loki cc pdx edu jim william ac freenet carleton ca colin henein ad cat axel dunkel al academ mty itesm mx jesu sanchez pe andrea uniti ncsu edu anugula badland nodak edu ramakrishna reddi anugula app sneak kodak com robert app arperd mik uki edu alicia perdu baind gov ca dave bain balamut morri hac com morri balamut bch juliet caltech edu bryan hathorn bernsteinn lonexa admin rl af mil norman bernstein bgain ollamh ucd brian gain bgeer beorn sim es com bob geer bjorn larsen delab sintef bjorn larsen bobw hpsadwc sad hp com bob waltenspiel bock vsikp uni muenster dirk bock bruce uxb liverpool ac uk bruce stephen bspencer binklei cs mcgill ca brian spencer claudia lonexa admin rl af mil claudia servadio coyn compass da com tomd compass da com thoma donnelli constabil lonexa admin rl af mil dian constabil csc coast ucsd edu charl coughran curtech sb unh edu stephani bradlei swift debrum msgate corp appl com brenda debrum dlb fanni wash inmet com david barton dlg midwai uchicago edu deborah lynn gillaspi dougb comm mot com dougla bank dr sunsrvr cci com dale seim dt cs hub ucsb edu david goggin ed titipu resun com edward reid edmoor hpvclc vcd hp com ed moor emilio accur com elizabeth milio ewc hplb hpl hp com enrico coiera feathr bluejai ampakz enet dec com franklig ga uug arizona edu gregori franklin fsspr acad alaska edu gabe angu mi org gabe helou gasp medg lc mit edu isaac kohan gavin praxi uk gavin finni geir millstein tf tele geir millstein ggurman cori berkelei edu gail gurman ggw wolv durham nc gregori woodburi gmalet surfer win net gari malet gonzalez suhep phy syr edu gabriela gonzalez greenlaw oasi dt navi mil leila thoma grm andrew cmu edu gretchen miller halderc cs rpi edu carol halder handelap duvm bitnet pucc princeton edu phil handel hc nyongwa cam org hed chrisco nrl navi mil hubert hed herbison lassi ucx lkg dec com hosch iscsvax uni edu kathleen hosch hrubin pop stat purdu edu herman rubin hudsoib auducadm duc auburn edu ingrid hudson huff mcclb med nyu edu edward huff huffman ingr com gari huffman huynh_ estd nrl navi mil minh huynh ishbeld cix compulink uk ishbel donkin jame langdel eng sun com jame langdel jami ssd intel com jami weisbrod jamyer netcom com john myer jc crosfield uk jerri cullingford jcobb garnet acn fsu edu jame cobb jesup cbmvax cbm commodor com randel jesup joannm hpcc corp hp com joann mcgowan joep dap csiro au joe petranov john burton acenet auburn edu john burton jr johncha comm mot com jorgensonk cc uvcc edu keith jorgenson jpsum mik uki edu joei sum jtm ucsfvm ucsf edu john maynard julien skcla monsanto com kaminski netcom com peter kaminski kerri citr uq oz au kerri raymond kieran world std com aaron dickei kolar spot colorado edu jennif lynn kolar kriguer tc com marc kriguer lauri lonexa admin rl af mil lauri kei lee hal com lee boylan lmt po cwru edu lia treffman luni lehigh edu lusgr chili cc lehigh edu stephen roseman beamish in gu edu au marilyn beamish rich en gu edu au mauric rich maa cdfsga fnal gov peter maa marilyn lonexa admin rl af mil marilyn tucker markv hpvcivm vcd hp com mark vanderford maschler vm huji ac il michael maschler mcb net bio net michael berch mcdai ux cso uiuc edu marriann dai mcookson flute calpoli edu melynda titipu resun com melynda reid mfc isr harvard edu mauricio contrera mg wpi edu martha gunnarson mhollowa libserv ic sunysb edu michael hollowai misha abacu concordia ca misha glouberman mjb cs brown edu manish butt moflngan vax tcd margaret flanagan muir idiom berkelei ca david muir sharnoff trebi southampton ac uk trebi hookei durham ac uk hookei nanci block eng sun com nanci block ndallen node hub org nigel allen nlemur eec umich edu nigel lemur nlr nei nih gov nathan rohrer pam hpfcmp fc hp com pam sullivan papresco undergrad math uwaterloo ca paul prescod paslowp cs rpi edu pam paslow phil unet umn edu phil lindberg pillinc gov ca christoph pill pkane cisco com peter kane pmmuggli midwai ecn uoknor edu paulin muggli popelka odysseu uchicago edu glenn popelka pulkka cs washington edu aaron pulkka pwatkin med unc edu pat watkin rbnsn mosaic shearson com ken robinson rmasten magnu ac ohio state edu roger masten robyn media mit edu robyn kozierok rolf green mathematik uni stuttgart rolf schreiber sageman cup portal com sasjc unx sa com joan stout sca space physic uiowa edu scott allendorf scottjor delphi com scrl hplb hpl hp com sc vecti demon uk stuart squibb shan techop crai com sharan kalwani sharen iscnvx lmsc lockhe com sharen rund shazam unh edu matthew thompson shipman csab larc nasa gov floyd shipman shoppa erin caltech edu tim shoppa sjsmith cs umd edu stephen joseph smith slilli cs bradlei edu susan lilli steveo world std com steven orr surendar ivi wpi edu surendar chandra swkirch sun nrl navi mil steven kirchoef s_fagan twu edu liz fagan taryn arizvm ccit arizona edu taryn westergaard thoma taylor gagm chi il thoma taylor tima cfsmo honeywel com timothi aanerud tsamuel gollum relai nswc navi mil toni samuel uicvm uic edu mari jacob vstern gte com vanessa stern wahlgren haida van wti com jame wahlgren waldref tv tv tek com greg waldref waterf pyrsea sea pyramid com dougla waterfal weineja teomail jhuapl edu wgrant informix com william grant wingb underdal unisa edu au brian wing yeager mscf med upenn edu yozzo watson ibm com ralph yozzo ysharma yamuna ingr com yamuna sharma beach utmb edu molli hamilton zulu iesd auc dk bjoern gregersen charter misc health diabet appear charter misc health diabet unmoder purpos misc health diabet provid forum discuss issu pertain diabet manag diet activ medicin schedul blood glucos control exercis medic breakthrough group address issu manag type insulin depend type ii non insulin depend diabet technic discuss gener support discuss relev diabet welcom post misc heath diabet intend discuss purpos wai constru medic advic diabet medic condit requir direct supervis primari health care physician end charter steve kirchoef code kirchoef estd nrl navi mil naval research laboratori microwav technolog branch washington dc electron sci tech divis\n",
      "9. sschaff roc slac stanford edu stephen schaffner subject ancient book organ stanford linear acceler center line articl apr atho rutger edu whheydt pbhya pacbel com wilson heydt write date oldest extant text nt feel civil war coupl thousand year extant text written adjust larg illiter popul copi manuscript hand consider better feel punic war peloponnesian war spell option event classic histori close event think oldest extent manuscript case steve schaffner sschaff unixhub slac stanford edu opinion express slac stanford univers doe\n",
      "10. warlord mit edu derek atkin subject clipper confer call organ massachusett institut technolog line nntp post host podg mit edu repli smb research att com messag sun apr gmt articl apr ulyss att com smb research att com steven bellovin write articl netnew upenn edu feelei cattel psych upenn edu wm michael feelei write curiou clipper chip handl confer call clipper encrypt ve seen number design gener involv multi line cleartext bridg depend encrypt long kei exampl vat internet audio tool confer encrypt session unfortun site work cpu sound good differ site neccessarili clear text bridg total intern site involv convers derek derek atkin mit electr engin scienc secretari mit student inform process board sipb mit media laboratori speech research group warlord mit edu pp asel nwh\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Initialize Elasticsearch client with URL\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "# Load the pre-trained FastText model\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "# Get user query\n",
    "user_query = input('Enter your query: ')\n",
    "\n",
    "# Preprocess the user query\n",
    "tokens = gensim.utils.simple_preprocess(user_query.lower())\n",
    "stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "preprocessed_query = ' '.join(stemmed_tokens)\n",
    "\n",
    "# Generate the vector for the user query by averaging the vectors of its tokens\n",
    "vector_sum = 0\n",
    "count = 0\n",
    "for token in preprocessed_query.split():\n",
    "    if token in model.wv:\n",
    "        vector_sum += model.wv[token]\n",
    "        count += 1\n",
    "if count > 0:\n",
    "    query_vector = vector_sum / count\n",
    "\n",
    "    # Search for similar documents using Elasticsearch\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'script_score': {\n",
    "                'query': {\n",
    "                    'match_all': {}\n",
    "                },\n",
    "                'script': {\n",
    "                    'source': 'cosineSimilarity(params.query_vector, \"vector\") + 1.0',\n",
    "                    'params': {\n",
    "                        'query_vector': query_vector.tolist()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Print the top 10 most similar documents\n",
    "    print('Top 10 most similar documents:')\n",
    "    for i, hit in enumerate(search_results[:10]):\n",
    "        print(f'{i+1}. {hit[\"_source\"][\"text\"]}')\n",
    "else:\n",
    "    print('No valid tokens in query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 7975\n",
      "2. 9295\n",
      "3. 650\n",
      "4. 14782\n",
      "5. 3108\n",
      "6. 541\n",
      "7. 547\n",
      "8. 18752\n",
      "9. 8914\n",
      "10. 795\n",
      "11. 14352\n",
      "12. 11028\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Initialize Elasticsearch client with URL\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "# Load the pre-trained FastText model\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "# Get user query\n",
    "user_query = input('Enter your query: ')\n",
    "\n",
    "index_name = 'my_index'\n",
    "\n",
    "# Preprocess the user query\n",
    "tokens = gensim.utils.simple_preprocess(user_query.lower())\n",
    "stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "preprocessed_query = ' '.join(stemmed_tokens)\n",
    "\n",
    "# Construct the Elasticsearch query for the current query using BM25 similarity\n",
    "search_body = {\n",
    "    'query': {\n",
    "        'match': {\n",
    "            'text': {\n",
    "                'query': preprocessed_query,\n",
    "                'analyzer': 'standard'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    '_source': {\n",
    "        'includes': ['text']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the search and retrieve the top k documents\n",
    "search_results = es.search(index=index_name, body=search_body)['hits']['hits']\n",
    "\n",
    "for i, hit in enumerate(search_results[:12]):\n",
    "    print(f'{i+1}. {hit[\"_id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_queries = [\"har write keyword tvtwm icon manag need help resourc bind tvtwm like icon manag iconifi window show icon list pan section virtual desktop try deiconifi window icon sp earlier like window deiconifi current region resourc us\",\n",
    "                     \"es com blain gardner write articl bong kfp slac mac slac stanford edu bong slac stanford edu eric bong write articl gp cbnew\",\n",
    "                     \"tmc spartan ac brocku ca tim ciceran subject turn photograph imag thermal print neg organ brock univers st catharin ontario newsread tin version pl line jennif\",\n",
    "                     \"miss point think ll admit atheist lot sleev suspect nah encourag peopl learn atheism littl atheist sleev suspect actual meager want\",\n",
    "                     \"nynexst com robert silver write send rush linbaugh clinton take awai right privaci govt standard take peopl lot monei drug dealer abl justifi de stuff slam clinton air rob recal rush sai compuserv account want mail need account number mail gatewai\",\n",
    "                     \"enjoi lunch saturdai foodi milford nh assort nedod folk dean cookson ye left countri mention wire diagram\",\n",
    "                     \"superior carleton ca mike richardson write lot good point mormon found father hardli great religi freedom histori read form opinion left practic religi freedom practic\",\n",
    "                     \"acceler manufactur lasermast eden prairi mn willi vill walveranta tel fax linda av apt finland oakland ca fax automat recogn usa email\",\n",
    "                     \"carolina state univers project eo line articl apr\",\n",
    "                     \"univers\"]\n",
    "\n",
    "relevant_docs = [\n",
    "    {\"99\",\"357\",\"3248\",\"5079\",\"9773\",\"12617\",\"9794\",\"1239\",\"5701\",\"3643\"},\n",
    "    {\"139\",\"7390\",\"13104\",\"8580\",\"5532\",\"8560\",\"4259\",\"18593\",\"544\",\"2231\"},\n",
    "    {\"164\",\"111\",\"9973\",\"3135\",\"18786\",\"1258\",\"10921\",\"2003\",\"7819\",\"7947\"},\n",
    "    {\"209\",\"11087\",\"7258\",\"3000\",\"16918\",\"8940\",\"12373\",\"11166\",\"12000\",\"5652\"},\n",
    "    {\"812\",\"5910\",\"13658\",\"8966\",\"780\",\"11642\",\"18667\",\"3269\",\"7040\",\"8780\"},\n",
    "    {\"650\",\"7975\",\"9295\",\"14780\",\"3108\",\"541\",\"547\",\"18752\",\"8915\",\"795\"},\n",
    "    {\"652\",\"18394\",\"3180\",\"14949\",\"18614\",\"18672\",\"14840\",\"2832\",\"8668\",\"18455\"},\n",
    "    {\"456\",\"411\",\"6428\",\"12170\",\"2850\",\"17151\",\"13703\",\"16548\",\"4096\",\"6969\"},\n",
    "    {\"496\",\"5580\",\"7619\",\"9393\",\"8763\",\"18500\",\"3382\",\"5552\",\"5457\",\"12792\"},\n",
    "    {\"726\",\"730\",\"7945\",\"700\",\"17115\",\"15673\",\"7900\",\"10929\",\"14553\",\"5311\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = [\n",
    "    {\"99\",\"357\",\"3248\",\"5079\",\"9773\",\"12617\",\"9794\",\"1239\",\"5701\",\"3643\"},\n",
    "    {\"139\",\"7390\",\"13104\",\"8580\",\"5532\",\"8560\",\"4259\",\"18593\",\"544\",\"2231\"},\n",
    "    {\"164\",\"111\",\"9973\",\"3135\",\"18786\",\"1258\",\"10921\",\"2003\",\"7819\",\"7947\"},\n",
    "    {\"209\",\"11087\",\"7258\",\"3000\",\"16918\",\"8940\",\"12373\",\"11166\",\"12000\",\"5652\"},\n",
    "    {\"812\",\"5910\",\"13658\",\"8966\",\"780\",\"11642\",\"18667\",\"3269\",\"7040\",\"8780\"},\n",
    "    {\"650\",\"7975\",\"9295\",\"14780\",\"3108\",\"541\",\"547\",\"18752\",\"8915\",\"795\"},\n",
    "    {\"652\",\"18394\",\"3180\",\"14949\",\"18614\",\"18672\",\"14840\",\"2832\",\"8668\",\"18455\"},\n",
    "    {\"456\",\"411\",\"6428\",\"12170\",\"2850\",\"17151\",\"13703\",\"16548\",\"4096\",\"6969\"},\n",
    "    {\"496\",\"5580\",\"7619\",\"9393\",\"8763\",\"18500\",\"3382\",\"5552\",\"5457\",\"12792\"},\n",
    "    {\"726\",\"730\",\"7945\",\"700\",\"17115\",\"15673\",\"7900\",\"10929\",\"14553\",\"5311\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision: 0.3\n",
      "Mean Recall: 0.3\n",
      "Mean Average Precision: 0.31157407407407406\n",
      "Mean nDCG: 0.7795429892889458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rushabh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_nDCG(ranked_relevance):\n",
    "    ideal_ranking = sorted(ranked_relevance, reverse=True)\n",
    "\n",
    "    # Calculate the discounted cumulative gain (DCG)\n",
    "    dcg = 0\n",
    "    for i in range(len(ranked_relevance)):\n",
    "        dcg += (2 ** ranked_relevance[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the ideal discounted cumulative gain (IDCG)\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_ranking)):\n",
    "        idcg += (2 ** ideal_ranking[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the nDCG\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dcg / idcg\n",
    "\n",
    "# k = 10  # The number of top documents to consider\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "average_precision_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "\n",
    "for i, query in enumerate(benchmark_queries):\n",
    "    relevant_doc = relevant_docs[i]  # Retrieve relevant documents for the query\n",
    "\n",
    "    # Preprocess the user query\n",
    "    tokens = gensim.utils.simple_preprocess(query.lower())\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    preprocessed_query = ' '.join(stemmed_tokens)\n",
    "\n",
    "    # Generate the vector for the user query by averaging the vectors of its tokens\n",
    "    vector_sum = 0\n",
    "    count = 0\n",
    "    for token in preprocessed_query.split():\n",
    "        if token in model.wv:\n",
    "            vector_sum += model.wv[token]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        query_vector = vector_sum / count\n",
    "    \n",
    "    # Construct the Elasticsearch query for the current query\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'script_score': {\n",
    "                'query': {\n",
    "                    'match_all': {}\n",
    "                },\n",
    "                'script': {\n",
    "                    'source': 'cosineSimilarity(params.query_vector, \"vector\") + 1.0',\n",
    "                    'params': {\n",
    "                        'query_vector': query_vector.tolist()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search and retrieve the top 10 documents\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Calculate Precision@K and Recall@K\n",
    "    retrieved_doc_ids = [hit[\"_id\"] for hit in search_results]\n",
    "\n",
    "    # Initialize variables for TP, TN, FP, FN\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    for doc in retrieved_doc_ids:\n",
    "        if doc in relevant_doc:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    \n",
    "    for doc in relevant_doc:\n",
    "        if doc not in retrieved_doc_ids:\n",
    "            FN += 1\n",
    "    \n",
    "    total_documents = len(retrieved_doc_ids)\n",
    "    TN = total_documents - (TP + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Calculate Average Precision\n",
    "    relevance_scores = [1 if doc_id in relevant_doc else 0 for doc_id in retrieved_doc_ids]\n",
    "    k = len(relevant_doc)\n",
    "    average_precision = average_precision_score(relevance_scores, range(1, k+1))\n",
    "    average_precision_scores.append(average_precision)\n",
    "\n",
    "    # Calculate nDCG\n",
    "    ranked_relevance = [1 if doc_id in relevant_doc else 0 for doc_id in retrieved_doc_ids]\n",
    "    ndcg = calculate_nDCG(ranked_relevance)\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    # Calculate the ideal ranking\n",
    "    ideal_ranking = sorted(ranked_relevance, reverse=True)\n",
    "\n",
    "    # Calculate the discounted cumulative gain (DCG)\n",
    "    dcg = 0\n",
    "    for i in range(len(ranked_relevance)):\n",
    "        dcg += (2 ** ranked_relevance[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the ideal discounted cumulative gain (IDCG)\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_ranking)):\n",
    "        idcg += (2 ** ideal_ranking[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the nDCG\n",
    "    if idcg == 0:\n",
    "        ndcg = 0\n",
    "    else:\n",
    "        ndcg = dcg / idcg\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "# Calculate the mean of each metric\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_average_precision = np.mean(average_precision_scores)\n",
    "mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "# Print or return the results\n",
    "print(f\"Mean Precision: {mean_precision}\")\n",
    "print(f\"Mean Recall: {mean_recall}\")\n",
    "print(f\"Mean Average Precision: {mean_average_precision}\")\n",
    "print(f\"Mean nDCG: {mean_ndcg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision: 0.55\n",
      "Mean Recall: 0.55\n",
      "Mean Average Precision: 0.5195287226001513\n",
      "Mean nDCG: 0.8183706974277765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rushabh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_nDCG(ranked_relevance):\n",
    "    ideal_ranking = sorted(ranked_relevance, reverse=True)\n",
    "\n",
    "    # Calculate the discounted cumulative gain (DCG)\n",
    "    dcg = 0\n",
    "    for i in range(len(ranked_relevance)):\n",
    "        dcg += (2 ** ranked_relevance[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the ideal discounted cumulative gain (IDCG)\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_ranking)):\n",
    "        idcg += (2 ** ideal_ranking[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the nDCG\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dcg / idcg\n",
    "\n",
    "# k = 10  # The number of top documents to consider\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "average_precision_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "\n",
    "for i, query in enumerate(benchmark_queries):\n",
    "    relevant_doc = relevant_docs[i]  # Retrieve relevant documents for the query\n",
    "\n",
    "    # Preprocess the user query\n",
    "    tokens = gensim.utils.simple_preprocess(query.lower())\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    preprocessed_query = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    # Construct the Elasticsearch query for the current query\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'match': {\n",
    "                'text': {\n",
    "                    'query': preprocessed_query,\n",
    "                    'analyzer': 'standard'\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search and retrieve the top 10 documents\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Calculate Precision@K and Recall@K\n",
    "    retrieved_doc_ids = [hit[\"_id\"] for hit in search_results]\n",
    "\n",
    "    # Initialize variables for TP, TN, FP, FN\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    for doc in retrieved_doc_ids:\n",
    "        if doc in relevant_doc:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    \n",
    "    for doc in relevant_doc:\n",
    "        if doc not in retrieved_doc_ids:\n",
    "            FN += 1\n",
    "    \n",
    "    total_documents = len(retrieved_doc_ids)\n",
    "    TN = total_documents - (TP + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Calculate Average Precision\n",
    "    relevance_scores = [1 if doc_id in relevant_doc else 0 for doc_id in retrieved_doc_ids]\n",
    "    k = len(relevant_doc)\n",
    "    average_precision = average_precision_score(relevance_scores, range(1, k+1))\n",
    "    average_precision_scores.append(average_precision)\n",
    "\n",
    "    # Calculate nDCG\n",
    "    ranked_relevance = [1 if doc_id in relevant_doc else 0 for doc_id in retrieved_doc_ids]\n",
    "    ndcg = calculate_nDCG(ranked_relevance)\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "    # Calculate the ideal ranking\n",
    "    ideal_ranking = sorted(ranked_relevance, reverse=True)\n",
    "\n",
    "    # Calculate the discounted cumulative gain (DCG)\n",
    "    dcg = 0\n",
    "    for i in range(len(ranked_relevance)):\n",
    "        dcg += (2 ** ranked_relevance[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the ideal discounted cumulative gain (IDCG)\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_ranking)):\n",
    "        idcg += (2 ** ideal_ranking[i] - 1) / (math.log2(i + 2))\n",
    "\n",
    "    # Calculate the nDCG\n",
    "    if idcg == 0:\n",
    "        ndcg = 0\n",
    "    else:\n",
    "        ndcg = dcg / idcg\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "# Calculate the mean of each metric\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_average_precision = np.mean(average_precision_scores)\n",
    "mean_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "# Print or return the results\n",
    "print(f\"Mean Precision: {mean_precision}\")\n",
    "print(f\"Mean Recall: {mean_recall}\")\n",
    "print(f\"Mean Average Precision: {mean_average_precision}\")\n",
    "print(f\"Mean nDCG: {mean_ndcg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved: retrieval_results_wordvec.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create a list to store the data for the CSV file\n",
    "csv_data = []\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "average_precision_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "for i, query in enumerate(benchmark_queries):\n",
    "    relevant_doc = relevant_docs[i]  # Retrieve relevant documents for the query\n",
    "\n",
    "    # Preprocess the user query\n",
    "    tokens = gensim.utils.simple_preprocess(query.lower())\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    preprocessed_query = ' '.join(stemmed_tokens)\n",
    "\n",
    "    # Generate the vector for the user query by averaging the vectors of its tokens\n",
    "    vector_sum = 0\n",
    "    count = 0\n",
    "    for token in preprocessed_query.split():\n",
    "        if token in model.wv:\n",
    "            vector_sum += model.wv[token]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        query_vector = vector_sum / count\n",
    "    \n",
    "    # Construct the Elasticsearch query for the current query\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'script_score': {\n",
    "                'query': {\n",
    "                    'match_all': {}\n",
    "                },\n",
    "                'script': {\n",
    "                    'source': 'cosineSimilarity(params.query_vector, \"vector\") + 1.0',\n",
    "                    'params': {\n",
    "                        'query_vector': query_vector.tolist()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search and retrieve the top 10 documents\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Create a list of lists with the data for the current query\n",
    "    query_data = []\n",
    "    for hit in search_results:\n",
    "        doc_id = hit[\"_id\"]\n",
    "        cosine_score = hit[\"_score\"]\n",
    "        is_relevant = 1 if doc_id in relevant_doc else 0\n",
    "        query_data.append([query, doc_id, cosine_score - 1, is_relevant])\n",
    "\n",
    "    # Append the query data to the CSV data\n",
    "    csv_data.extend(query_data)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"retrieval_results_wordvec.csv\"\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header row\n",
    "    csv_writer.writerow([\"Query\", \"Doc_ID\", \"Cosine_Score\", \"Relevance_Judgment\"])\n",
    "    # Write the query data\n",
    "    csv_writer.writerows(csv_data)\n",
    "\n",
    "# Print or return the results\n",
    "print(f\"CSV file saved: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved: retrieval_results_bm25.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create a list to store the data for the CSV file\n",
    "csv_data = []\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "average_precision_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "for i, query in enumerate(benchmark_queries):\n",
    "    relevant_doc = relevant_docs[i]  # Retrieve relevant documents for the query\n",
    "\n",
    "    # Preprocess the user query\n",
    "    tokens = gensim.utils.simple_preprocess(query.lower())\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    preprocessed_query = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    # Construct the Elasticsearch query for the current query\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'match': {\n",
    "                'text': {\n",
    "                    'query': preprocessed_query,\n",
    "                    'analyzer': 'standard'\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search and retrieve the top 10 documents\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Create a list of lists with the data for the current query\n",
    "    query_data = []\n",
    "    for hit in search_results:\n",
    "        doc_id = hit[\"_id\"]\n",
    "        cosine_score = hit[\"_score\"]\n",
    "        is_relevant = 1 if doc_id in relevant_doc else 0\n",
    "        query_data.append([query, doc_id, cosine_score - 1, is_relevant])\n",
    "\n",
    "    # Append the query data to the CSV data\n",
    "    csv_data.extend(query_data)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"retrieval_results_bm25.csv\"\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header row\n",
    "    csv_writer.writerow([\"Query\", \"Doc_ID\", \"Cosine_Score\", \"Relevance_Judgment\"])\n",
    "    # Write the query data\n",
    "    csv_writer.writerows(csv_data)\n",
    "\n",
    "# Print or return the results\n",
    "print(f\"CSV file saved: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved: precision_recall_data_wordvec.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create a list to store the precision and recall data\n",
    "precision_recall_data = []\n",
    "\n",
    "k = 10  # The number of top documents to consider\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "for i, query in enumerate(benchmark_queries):\n",
    "    relevant_doc = relevant_docs[i]  # Retrieve relevant documents for the query\n",
    "\n",
    "    # Preprocess the user query\n",
    "    tokens = gensim.utils.simple_preprocess(query.lower())\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    preprocessed_query = ' '.join(stemmed_tokens)\n",
    "\n",
    "    # Generate the vector for the user query by averaging the vectors of its tokens\n",
    "    vector_sum = 0\n",
    "    count = 0\n",
    "    for token in preprocessed_query.split():\n",
    "        if token in model.wv:\n",
    "            vector_sum += model.wv[token]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        query_vector = vector_sum / count\n",
    "    \n",
    "    # Construct the Elasticsearch query for the current query\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'script_score': {\n",
    "                'query': {\n",
    "                    'match_all': {}\n",
    "                },\n",
    "                'script': {\n",
    "                    'source': 'cosineSimilarity(params.query_vector, \"vector\") + 1.0',\n",
    "                    'params': {\n",
    "                        'query_vector': query_vector.tolist()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search and retrieve the top 10 documents\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Calculate Precision@K and Recall@K\n",
    "    retrieved_doc_ids = [hit[\"_id\"] for hit in search_results]\n",
    "    true_positives = len(set(retrieved_doc_ids).intersection(relevant_doc))\n",
    "    false_positive = len(set(retrieved_doc_ids)) - true_positives\n",
    "    false_negative = len(relevant_doc) - true_positives\n",
    "    precision = true_positives / (true_positives + false_positive)\n",
    "    recall = true_positives / (true_positives + false_negative)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Append precision and recall values for the current query\n",
    "    precision_recall_data.append([query, precision, recall])\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"precision_recall_data_wordvec.csv\"\n",
    "\n",
    "# Write the precision and recall data to a CSV file\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header row\n",
    "    csv_writer.writerow([\"Query\", \"Precision\", \"Recall\"])\n",
    "    # Write the precision and recall data\n",
    "    csv_writer.writerows(precision_recall_data)\n",
    "\n",
    "# Print or return the results\n",
    "print(f\"CSV file saved: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved: precision_recall_data_bm25.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create a list to store the precision and recall data\n",
    "precision_recall_data = []\n",
    "\n",
    "k = 10  # The number of top documents to consider\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "model = gensim.models.FastText.load('model.bin')\n",
    "\n",
    "for i, query in enumerate(benchmark_queries):\n",
    "    relevant_doc = relevant_docs[i]  # Retrieve relevant documents for the query\n",
    "\n",
    "    # Preprocess the user query\n",
    "    tokens = gensim.utils.simple_preprocess(query.lower())\n",
    "    stemmed_tokens = [gensim.parsing.porter.PorterStemmer().stem(token) for token in tokens if token not in gensim.parsing.preprocessing.STOPWORDS]\n",
    "    preprocessed_query = ' '.join(stemmed_tokens)\n",
    "\n",
    "    # Generate the vector for the user query by averaging the vectors of its tokens\n",
    "    vector_sum = 0\n",
    "    count = 0\n",
    "    for token in preprocessed_query.split():\n",
    "        if token in model.wv:\n",
    "            vector_sum += model.wv[token]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        query_vector = vector_sum / count\n",
    "    \n",
    "    # Construct the Elasticsearch query for the current query\n",
    "    search_body = {\n",
    "        'query': {\n",
    "            'script_score': {\n",
    "                'query': {\n",
    "                    'match_all': {}\n",
    "                },\n",
    "                'script': {\n",
    "                    'source': 'cosineSimilarity(params.query_vector, \"vector\") + 1.0',\n",
    "                    'params': {\n",
    "                        'query_vector': query_vector.tolist()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        '_source': {\n",
    "            'includes': ['text']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search and retrieve the top 10 documents\n",
    "    search_results = es.search(index='my_index', body=search_body)['hits']['hits']\n",
    "\n",
    "    # Calculate Precision@K and Recall@K\n",
    "    retrieved_doc_ids = [hit[\"_id\"] for hit in search_results]\n",
    "    true_positives = len(set(retrieved_doc_ids).intersection(relevant_doc))\n",
    "    false_positive = len(set(retrieved_doc_ids)) - true_positives\n",
    "    false_negative = len(relevant_doc) - true_positives\n",
    "    precision = true_positives / (true_positives + false_positive)\n",
    "    recall = true_positives / (true_positives + false_negative)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Append precision and recall values for the current query\n",
    "    precision_recall_data.append([query, precision, recall])\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"precision_recall_data_bm25.csv\"\n",
    "\n",
    "# Write the precision and recall data to a CSV file\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header row\n",
    "    csv_writer.writerow([\"Query\", \"Precision\", \"Recall\"])\n",
    "    # Write the precision and recall data\n",
    "    csv_writer.writerows(precision_recall_data)\n",
    "\n",
    "# Print or return the results\n",
    "print(f\"CSV file saved: {csv_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
